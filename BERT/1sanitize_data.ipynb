{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji\n",
    "#!pip install pydantic==1.10.2.\n",
    "#!pip3 install spacy\n",
    "#!pip install gensim\n",
    "#!pip install wordcloud\n",
    "#!pip install openpyxl\n",
    "#!pip install XlsxWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing emojis from text\n",
    "#Refrence 1 : https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "#Refrence 2 : https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "\n",
    "def give_emoji_free_text(text):\n",
    "    \"\"\"\n",
    "    Removes emoji's from tweets\n",
    "    Accepts:\n",
    "        Text (tweets)\n",
    "    Returns:\n",
    "        Text (emoji free tweets)\n",
    "    \"\"\"\n",
    "    emoji_list = [c for c in text if c in emoji.EMOJI_DATA]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def url_free_text(text):\n",
    "    '''\n",
    "    Cleans text from urls\n",
    "    '''\n",
    "    text = re.sub (r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    \n",
    "    #text = re.sub(r'http\\S+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def to_datetime(date):\n",
    "    \"\"\"\n",
    "    Converts a numpy datetime64 object to a python datetime object \n",
    "    Input:\n",
    "      date - a np.datetime64 object\n",
    "    Output:\n",
    "      DATE - a python datetime object\n",
    "    \"\"\"\n",
    "    timestamp = ((date - np.datetime64('1970-01-01T00:00:00'))\n",
    "                 / np.timedelta64(1, 's'))\n",
    "    return datetime.utcfromtimestamp(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "data = read_excel(\"original_tweets.xlsx\",sheet_name = 'original tweet data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3172, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Converting the dataset to pandas DataFrame and renaming the columns \n",
    "df_original_tweet = pd.DataFrame(data['text'].tolist())\n",
    "\n",
    "df_original_tweet = df_original_tweet.rename(columns={0:'original_tweets'})\n",
    "df_original_tweet = df_original_tweet.rename(columns={1:'tweet_id'})\n",
    "df_original_tweet = df_original_tweet.rename(columns={2:'company_name'})#company_name\n",
    "df_original_tweet = df_original_tweet.rename(columns={3:'created_at'})#created_at\n",
    "\n",
    "\n",
    "df_original_tweet['company_name'] = data['company_name']\n",
    "df_original_tweet['created_at'] = data['created_at']\n",
    "df_original_tweet['tweet_id'] = data['tweet_id']\n",
    "df_original_tweet.head(10)\n",
    "\n",
    "df_original_tweet.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3172, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "# Apply the function above and get tweets free of emoji's\n",
    "call_emoji_free = lambda x: give_emoji_free_text(x)\n",
    "\n",
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "df_original_tweet['emoji_free_tweets'] = df_original_tweet['original_tweets'].apply(call_emoji_free)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "\n",
    "df_original_tweet['sanitized_text'] = df_original_tweet['emoji_free_tweets'].apply(url_free_text)\n",
    "df_original_tweet.head(5)\n",
    "df_original_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by company and date\n",
    "#company_name='Amazon'\n",
    "#company_name = 'Amazon'\n",
    "#df_original_tweet = df_original_tweet.loc[df_original_tweet['company_name'] == company_name]\n",
    "df_original_tweet['created_at'] = pd.to_datetime(df_original_tweet['created_at']) # converting string in date object\n",
    "df_original_tweet = df_original_tweet.sort_values(by=\"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove links and mentions(@)\n",
    "import re\n",
    "def remove_usernames_links(tweet):\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) \n",
    "    tweet = re.sub('http[^\\s]+','',tweet)\n",
    "    return tweet\n",
    "df_original_tweet['sanitized_text'] = df_original_tweet['sanitized_text'].apply(remove_usernames_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract hash tag words into a new column named hash_tag_words\n",
    "import re\n",
    "def extract_hashtag_words(tweet):\n",
    "    hashtags = re.findall(\"#([a-zA-Z0-9_]{1,50})\", tweet)\n",
    "    return hashtags\n",
    "\n",
    "df_original_tweet['hash_tag_words'] = df_original_tweet['sanitized_text'].apply(extract_hashtag_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hash tag words from sanitized_text \n",
    "import re\n",
    "def remove_hashtag_words(tweet):\n",
    "    tweet = re.sub('#([a-zA-Z0-9_]{1,50})','',tweet)\n",
    "    return tweet\n",
    "\n",
    "df_original_tweet['sanitized_text'] = df_original_tweet['sanitized_text'].apply(remove_hashtag_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Text(1/2), 1/,2/ etc\n",
    "import re\n",
    "def remove_others(tweet):\n",
    "    tweet = tweet.replace(\"(\", \"\")\n",
    "    tweet = tweet.replace(\")\", \"\")\n",
    "    tweet = re.sub(\"[0-9]/\",'',tweet) # remove 1/,2/ etc\n",
    "    tweet = re.sub(\"Text [0-9]:\",'',tweet) # Text(1/2)\n",
    "    tweet = re.sub(\"[0-50].\",'',tweet) # 1. 2. etc\n",
    "    return tweet\n",
    "\n",
    "df_original_tweet['sanitized_text'] = df_original_tweet['sanitized_text'].apply(remove_others)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>company_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emoji_free_tweets</th>\n",
       "      <th>sanitized_text</th>\n",
       "      <th>hash_tag_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tomorrow, we walk out for real change. #google...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 00:38:58+00:00</td>\n",
       "      <td>1057794087955427328</td>\n",
       "      <td>Tomorrow, we walk out for real change. #google...</td>\n",
       "      <td>Tomorrow, we walk out for real change.</td>\n",
       "      <td>[googlewalkout, google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 01:19:09+00:00</td>\n",
       "      <td>1057804203895283712</td>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>[googlewalkout]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 02:46:11+00:00</td>\n",
       "      <td>1057826104965246976</td>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>[googlewalkout]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sasha_feather @hypatiadotca Thank you so much...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 03:29:24+00:00</td>\n",
       "      <td>1057836978954256385</td>\n",
       "      <td>@sasha_feather @hypatiadotca Thank you so much...</td>\n",
       "      <td>Thank you so much for the reminder! We’re on...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text (1/2):\\n1. An end to Forced Arbitration i...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 03:30:52+00:00</td>\n",
       "      <td>1057837349290287104</td>\n",
       "      <td>Text (1/2): 1. An end to Forced Arbitration in...</td>\n",
       "      <td>An end to Forced Arbitration in cases of har...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>6/ Maybe the scariest part about all of this i...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2021-12-17 20:06:53+00:00</td>\n",
       "      <td>1471934946625429510</td>\n",
       "      <td>6/ Maybe the scariest part about all of this i...</td>\n",
       "      <td>Maybe the scariest part about all of this is ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>7/ As workers, we’re disturbed. “This report i...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2021-12-17 20:06:53+00:00</td>\n",
       "      <td>1471934948336615430</td>\n",
       "      <td>7/ As workers, we’re disturbed. “This report i...</td>\n",
       "      <td>As workers, we’re disturbed. “This report is ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>8/ Thank you @kavehwaddell @ConsumerReports @g...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2021-12-17 20:06:53+00:00</td>\n",
       "      <td>1471934950073151496</td>\n",
       "      <td>8/ Thank you @kavehwaddell @ConsumerReports @g...</td>\n",
       "      <td>Thank you    for your important investigative...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>1/ I've worked for Apple since August 2015. \\n...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2021-12-20 14:50:08+00:00</td>\n",
       "      <td>1472942398946910211</td>\n",
       "      <td>1/ I've worked for Apple since August 2015. Ha...</td>\n",
       "      <td>I've worked for Apple since August . Harassme...</td>\n",
       "      <td>[appletoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>BREAKING: The SEC has ruled against Apple on a...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2021-12-21 22:13:08+00:00</td>\n",
       "      <td>1473416272163581952</td>\n",
       "      <td>BREAKING: The SEC has ruled against Apple on a...</td>\n",
       "      <td>BREAKING: The SEC has ruled against Apple on a...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3172 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        original_tweets company_name  \\\n",
       "0     Tomorrow, we walk out for real change. #google...       Google   \n",
       "1     We, Google employees and contractors, will wal...       Google   \n",
       "2     Google employees and contractors will be leavi...       Google   \n",
       "3     @sasha_feather @hypatiadotca Thank you so much...       Google   \n",
       "4     Text (1/2):\\n1. An end to Forced Arbitration i...       Google   \n",
       "...                                                 ...          ...   \n",
       "3168  6/ Maybe the scariest part about all of this i...       Amazon   \n",
       "3167  7/ As workers, we’re disturbed. “This report i...       Amazon   \n",
       "3169  8/ Thank you @kavehwaddell @ConsumerReports @g...       Amazon   \n",
       "3170  1/ I've worked for Apple since August 2015. \\n...        Apple   \n",
       "3171  BREAKING: The SEC has ruled against Apple on a...        Apple   \n",
       "\n",
       "                    created_at             tweet_id  \\\n",
       "0    2018-11-01 00:38:58+00:00  1057794087955427328   \n",
       "1    2018-11-01 01:19:09+00:00  1057804203895283712   \n",
       "2    2018-11-01 02:46:11+00:00  1057826104965246976   \n",
       "3    2018-11-01 03:29:24+00:00  1057836978954256385   \n",
       "4    2018-11-01 03:30:52+00:00  1057837349290287104   \n",
       "...                        ...                  ...   \n",
       "3168 2021-12-17 20:06:53+00:00  1471934946625429510   \n",
       "3167 2021-12-17 20:06:53+00:00  1471934948336615430   \n",
       "3169 2021-12-17 20:06:53+00:00  1471934950073151496   \n",
       "3170 2021-12-20 14:50:08+00:00  1472942398946910211   \n",
       "3171 2021-12-21 22:13:08+00:00  1473416272163581952   \n",
       "\n",
       "                                      emoji_free_tweets  \\\n",
       "0     Tomorrow, we walk out for real change. #google...   \n",
       "1     We, Google employees and contractors, will wal...   \n",
       "2     Google employees and contractors will be leavi...   \n",
       "3     @sasha_feather @hypatiadotca Thank you so much...   \n",
       "4     Text (1/2): 1. An end to Forced Arbitration in...   \n",
       "...                                                 ...   \n",
       "3168  6/ Maybe the scariest part about all of this i...   \n",
       "3167  7/ As workers, we’re disturbed. “This report i...   \n",
       "3169  8/ Thank you @kavehwaddell @ConsumerReports @g...   \n",
       "3170  1/ I've worked for Apple since August 2015. Ha...   \n",
       "3171  BREAKING: The SEC has ruled against Apple on a...   \n",
       "\n",
       "                                         sanitized_text  \\\n",
       "0             Tomorrow, we walk out for real change.      \n",
       "1     We, Google employees and contractors, will wal...   \n",
       "2     Google employees and contractors will be leavi...   \n",
       "3       Thank you so much for the reminder! We’re on...   \n",
       "4       An end to Forced Arbitration in cases of har...   \n",
       "...                                                 ...   \n",
       "3168   Maybe the scariest part about all of this is ...   \n",
       "3167   As workers, we’re disturbed. “This report is ...   \n",
       "3169   Thank you    for your important investigative...   \n",
       "3170   I've worked for Apple since August . Harassme...   \n",
       "3171  BREAKING: The SEC has ruled against Apple on a...   \n",
       "\n",
       "               hash_tag_words  \n",
       "0     [googlewalkout, google]  \n",
       "1             [googlewalkout]  \n",
       "2             [googlewalkout]  \n",
       "3                          []  \n",
       "4                          []  \n",
       "...                       ...  \n",
       "3168                       []  \n",
       "3167                       []  \n",
       "3169                       []  \n",
       "3170               [appletoo]  \n",
       "3171                       []  \n",
       "\n",
       "[3172 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")\n",
    "document = df_original_tweet['sanitized_text'].values.tolist()\n",
    "#pprint.pprint(document)\n",
    "# Load spacy\n",
    "# Make sure to restart the runtime after running installations and libraries tab\n",
    "#print(spacy.__version__)\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import Gensim and Wordcloud to use their stopwords as well and use the combined stopwords of ALL as the variable:\n",
    "ALL_STOP_WORDS\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from gensim.parsing.preprocessing import STOPWORDS as SW\n",
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "# Timing Start\n",
    "program_start_time = time.time()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "# Custom stopwords\n",
    "custom_stopwords = ['hi','\\n','\\n\\n', '&amp;', ' ', '.', '-', 'got', \"it's\", 'it’s', \"i'm\", 'i’m', 'im', 'want', 'like', 'cont', '$', '@','RT','rt','google','amazon','nyc','?','zurich','re','we']\n",
    "\n",
    "# Customize stop words by adding to the default list\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(custom_stopwords)\n",
    "\n",
    "# ALL_STOP_WORDS = spacy + gensim + wordcloud\n",
    "ALL_STOP_WORDS = STOP_WORDS.union(SW).union(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3172, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df_original_tweet['sanitized_text'], batch_size=500):\n",
    "    doc_tokens = []    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in ALL_STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower()) \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "# Makes tokens column\n",
    "df_original_tweet['unigrams'] = tokens\n",
    "\n",
    "# Make tokens a string again\n",
    "#df_original_tweet['tokens_back_to_text'] = [' '.join(map(str, l)) for l in df_original_tweet['unigrams']]\n",
    "\n",
    "# Timing End\n",
    "program_end_time = time.time()\n",
    "\n",
    "# View df\n",
    "#df[['sanitized_text','tokens','tokens_back_to_text']]\n",
    "df_original_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>company_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emoji_free_tweets</th>\n",
       "      <th>sanitized_text</th>\n",
       "      <th>hash_tag_words</th>\n",
       "      <th>unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tomorrow, we walk out for real change. #google...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 00:38:58+00:00</td>\n",
       "      <td>1057794087955427328</td>\n",
       "      <td>Tomorrow, we walk out for real change. #google...</td>\n",
       "      <td>Tomorrow, we walk out for real change.</td>\n",
       "      <td>[googlewalkout, google]</td>\n",
       "      <td>[tomorrow,, walk, real, change.,   ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 01:19:09+00:00</td>\n",
       "      <td>1057804203895283712</td>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>[googlewalkout]</td>\n",
       "      <td>[we,, employees, contractors,, walkout, novemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 02:46:11+00:00</td>\n",
       "      <td>1057826104965246976</td>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>[googlewalkout]</td>\n",
       "      <td>[employees, contractors, leaving, flyers, desk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sasha_feather @hypatiadotca Thank you so much...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 03:29:24+00:00</td>\n",
       "      <td>1057836978954256385</td>\n",
       "      <td>@sasha_feather @hypatiadotca Thank you so much...</td>\n",
       "      <td>Thank you so much for the reminder! We’re on...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[  , thank, reminder!, we’re, it,, sorry, lapse.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text (1/2):\\n1. An end to Forced Arbitration i...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 03:30:52+00:00</td>\n",
       "      <td>1057837349290287104</td>\n",
       "      <td>Text (1/2): 1. An end to Forced Arbitration in...</td>\n",
       "      <td>An end to Forced Arbitration in cases of har...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[  , end, forced, arbitration, cases, harassme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2/2):\\n4. A clear, uniform, globally inclusiv...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 03:31:55+00:00</td>\n",
       "      <td>1057837611891507200</td>\n",
       "      <td>(2/2): 4. A clear, uniform, globally inclusive...</td>\n",
       "      <td>A clear, uniform, globally inclusive process...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[  , clear,, uniform,, globally, inclusive, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@hypatiadotca @sasha_feather That’s awesome, w...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 03:36:14+00:00</td>\n",
       "      <td>1057838702330822656</td>\n",
       "      <td>@hypatiadotca @sasha_feather That’s awesome, w...</td>\n",
       "      <td>That’s awesome, we’ll use that feature in th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[  , that’s, awesome,, we’ll, use, feature, fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>More photos are coming in from the 40+ offices...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 10:46:51+00:00</td>\n",
       "      <td>1057947069506355200</td>\n",
       "      <td>More photos are coming in from the 40+ offices...</td>\n",
       "      <td>More photos are coming in from the + offices w...</td>\n",
       "      <td>[GoogleWalkout]</td>\n",
       "      <td>[photos, coming, +, offices, walking, today!, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Another angle of the #GoogleWalkout at Google ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 10:52:29+00:00</td>\n",
       "      <td>1057948484731584514</td>\n",
       "      <td>Another angle of the #GoogleWalkout at Google ...</td>\n",
       "      <td>Another angle of the  at Google Zürich</td>\n",
       "      <td>[GoogleWalkout]</td>\n",
       "      <td>[angle, zürich]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Google Dublin, we see you! Thanks for coming o...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2018-11-01 11:32:33+00:00</td>\n",
       "      <td>1057958568551464961</td>\n",
       "      <td>Google Dublin, we see you! Thanks for coming o...</td>\n",
       "      <td>Google Dublin, we see you! Thanks for coming o...</td>\n",
       "      <td>[GoogleWalkout]</td>\n",
       "      <td>[dublin,, you!, thanks, coming, today]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_tweets company_name  \\\n",
       "0  Tomorrow, we walk out for real change. #google...       Google   \n",
       "1  We, Google employees and contractors, will wal...       Google   \n",
       "2  Google employees and contractors will be leavi...       Google   \n",
       "3  @sasha_feather @hypatiadotca Thank you so much...       Google   \n",
       "4  Text (1/2):\\n1. An end to Forced Arbitration i...       Google   \n",
       "5  (2/2):\\n4. A clear, uniform, globally inclusiv...       Google   \n",
       "6  @hypatiadotca @sasha_feather That’s awesome, w...       Google   \n",
       "7  More photos are coming in from the 40+ offices...       Google   \n",
       "8  Another angle of the #GoogleWalkout at Google ...       Google   \n",
       "9  Google Dublin, we see you! Thanks for coming o...       Google   \n",
       "\n",
       "                 created_at             tweet_id  \\\n",
       "0 2018-11-01 00:38:58+00:00  1057794087955427328   \n",
       "1 2018-11-01 01:19:09+00:00  1057804203895283712   \n",
       "2 2018-11-01 02:46:11+00:00  1057826104965246976   \n",
       "3 2018-11-01 03:29:24+00:00  1057836978954256385   \n",
       "4 2018-11-01 03:30:52+00:00  1057837349290287104   \n",
       "5 2018-11-01 03:31:55+00:00  1057837611891507200   \n",
       "6 2018-11-01 03:36:14+00:00  1057838702330822656   \n",
       "7 2018-11-01 10:46:51+00:00  1057947069506355200   \n",
       "8 2018-11-01 10:52:29+00:00  1057948484731584514   \n",
       "9 2018-11-01 11:32:33+00:00  1057958568551464961   \n",
       "\n",
       "                                   emoji_free_tweets  \\\n",
       "0  Tomorrow, we walk out for real change. #google...   \n",
       "1  We, Google employees and contractors, will wal...   \n",
       "2  Google employees and contractors will be leavi...   \n",
       "3  @sasha_feather @hypatiadotca Thank you so much...   \n",
       "4  Text (1/2): 1. An end to Forced Arbitration in...   \n",
       "5  (2/2): 4. A clear, uniform, globally inclusive...   \n",
       "6  @hypatiadotca @sasha_feather That’s awesome, w...   \n",
       "7  More photos are coming in from the 40+ offices...   \n",
       "8  Another angle of the #GoogleWalkout at Google ...   \n",
       "9  Google Dublin, we see you! Thanks for coming o...   \n",
       "\n",
       "                                      sanitized_text           hash_tag_words  \\\n",
       "0          Tomorrow, we walk out for real change.     [googlewalkout, google]   \n",
       "1  We, Google employees and contractors, will wal...          [googlewalkout]   \n",
       "2  Google employees and contractors will be leavi...          [googlewalkout]   \n",
       "3    Thank you so much for the reminder! We’re on...                       []   \n",
       "4    An end to Forced Arbitration in cases of har...                       []   \n",
       "5    A clear, uniform, globally inclusive process...                       []   \n",
       "6    That’s awesome, we’ll use that feature in th...                       []   \n",
       "7  More photos are coming in from the + offices w...          [GoogleWalkout]   \n",
       "8            Another angle of the  at Google Zürich           [GoogleWalkout]   \n",
       "9  Google Dublin, we see you! Thanks for coming o...          [GoogleWalkout]   \n",
       "\n",
       "                                            unigrams  \n",
       "0               [tomorrow,, walk, real, change.,   ]  \n",
       "1  [we,, employees, contractors,, walkout, novemb...  \n",
       "2  [employees, contractors, leaving, flyers, desk...  \n",
       "3  [  , thank, reminder!, we’re, it,, sorry, lapse.]  \n",
       "4  [  , end, forced, arbitration, cases, harassme...  \n",
       "5  [  , clear,, uniform,, globally, inclusive, pr...  \n",
       "6  [  , that’s, awesome,, we’ll, use, feature, fu...  \n",
       "7  [photos, coming, +, offices, walking, today!, ...  \n",
       "8                                    [angle, zürich]  \n",
       "9             [dublin,, you!, thanks, coming, today]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build bigrams and trigrams\n",
    "import gensim\n",
    "bigram_phrases = gensim.models.Phrases(df_original_tweet['unigrams'], min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[df_original_tweet['unigrams']], threshold=100)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram[bigram[doc]] for doc in texts]\n",
    "\n",
    "bigrams = make_bigrams(df_original_tweet['unigrams'])\n",
    "trigrams = make_trigrams(df_original_tweet['unigrams'])\n",
    "#df_original_tweet['bigrams'] = bigrams\n",
    "df_original_tweet['n_grams'] = trigrams #Includes bigrams trigrams and unigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out unigrams\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "def filter_unigrams(df):\n",
    "    bi_tri_list = []\n",
    "    uni_list = []\n",
    "    data = df\n",
    "    for index, row in data.iterrows():\n",
    "        bi_tri = []\n",
    "        uni = []\n",
    "        if(type(row['n_grams'])!=None):\n",
    "            for word in row['n_grams']:\n",
    "                #if word.find('_')!=-1:\n",
    "                if re.search(\"([a-zA-Z0-9])_([a-zA-Z0-9])\", word):\n",
    "                    #pprint.pprint(word)\n",
    "                    bi_tri.append(word)\n",
    "                else:\n",
    "                    uni.append(word)\n",
    "\n",
    "            bi_tri_list.append(bi_tri)\n",
    "            uni_list.append(uni)\n",
    "            \n",
    "    return bi_tri_list,uni_list \n",
    "\n",
    "\n",
    "bi_tri_list, uni_list = filter_unigrams(df_original_tweet)\n",
    " \n",
    "#pprint.pprint(bi_tri_list)\n",
    "#pprint.pprint(uni_list)\n",
    "df_original_tweet['unigrams'] = uni_list\n",
    "df_original_tweet['bigrams_trigrams'] = bi_tri_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_words_bigrams)\n",
    "\n",
    "#These are names of places or people.\n",
    "words_to_remove_set = {\"amznclimate_fridaysforfuture\",\n",
    "                         \"copley_square\",\"googlewac_msworkers\",\n",
    "                         \"emahlee_marencosta\",\n",
    "                     \"jeff_bezos\",\"meredith_clairewaves\",\"timnit_gebru\",\"mountain_view\",\n",
    "                         \"san_bernardino\",\n",
    "                     \"dr_timnit\",\"dr_gebru\",\"dr_gebrus\",\n",
    "                         \"san_francisco\",\"new_york\",\n",
    "                         \"bay_area\",\"timnitgebru\",\n",
    "                         \"meredith\",\"wayfairwalkout\", \"tweetsofsandra_week\",\"riot_games\", \"githubdropice_notechforice\",\"notechforice_githubdropice\" }\n",
    "                        # {\"near_warehouses\",\"stay_tuned\",\n",
    "                        # \"board_directors\",\"temps_vendors\",\"software_engineer\",\n",
    "                        # \"press_release\",\"shareholder_meeting\",\"gas_companies\",\"tweetsofsandra_week\"}\n",
    "\n",
    "            \n",
    "def filter_places_and_people_names(df_original_tweet):\n",
    "    data = df_original_tweet\n",
    "    bigrams_filtered = []\n",
    "    unigrams_filtered = []\n",
    "    ngrams_filtered = []\n",
    "    for index, row in data.iterrows():\n",
    "        tmp = []\n",
    "        for word in row['bigrams_trigrams']:    \n",
    "            if word not in words_to_remove_set:\n",
    "                tmp.append(word)\n",
    "        bigrams_filtered.append(tmp)\n",
    "        tmp = []\n",
    "        for word in row['unigrams']:    \n",
    "            if word not in words_to_remove_set:\n",
    "                tmp.append(word)\n",
    "        unigrams_filtered.append(tmp)\n",
    "        tmp = []\n",
    "        for word in row['n_grams']:    \n",
    "            if word not in words_to_remove_set:\n",
    "                tmp.append(word)\n",
    "        ngrams_filtered.append(tmp)\n",
    "        \n",
    "    return unigrams_filtered, bigrams_filtered, ngrams_filtered\n",
    "            \n",
    "        \n",
    "unigrams_filtered, bigrams_filtered, ngrams_filtered =  filter_places_and_people_names(df_original_tweet)\n",
    "df_original_tweet['unigrams_filtered'] = unigrams_filtered\n",
    "df_original_tweet['bigrams_filtered'] = bigrams_filtered\n",
    "df_original_tweet['ngrams_filtered'] = ngrams_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tokens a string again\n",
    "df_original_tweet['unigrams_to_text'] = [' '.join(map(str, l)) for l in df_original_tweet['unigrams_filtered']]\n",
    "df_original_tweet['bigrams_to_text'] = [' '.join(map(str, l)) for l in df_original_tweet['bigrams_filtered']]\n",
    "df_original_tweet['ngram_to_text'] = [' '.join(map(str, l)) for l in df_original_tweet['ngrams_filtered']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3172, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_santanize = df_original_tweet[['tweet_id','original_tweets','company_name','ngram_to_text','unigrams_to_text','bigrams_to_text']].copy()\n",
    "df_santanize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>company_name</th>\n",
       "      <th>ngram_to_text</th>\n",
       "      <th>unigrams_to_text</th>\n",
       "      <th>bigrams_to_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1057794087955427328</td>\n",
       "      <td>Tomorrow, we walk out for real change. #google...</td>\n",
       "      <td>Google</td>\n",
       "      <td>tomorrow, walk real change.</td>\n",
       "      <td>tomorrow, walk real change.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1057804203895283712</td>\n",
       "      <td>We, Google employees and contractors, will wal...</td>\n",
       "      <td>Google</td>\n",
       "      <td>we, employees contractors, walkout november :a...</td>\n",
       "      <td>we, employees contractors, walkout november :a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1057826104965246976</td>\n",
       "      <td>Google employees and contractors will be leavi...</td>\n",
       "      <td>Google</td>\n",
       "      <td>employees contractors leaving flyers desks tom...</td>\n",
       "      <td>employees contractors leaving flyers desks tom...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1057836978954256385</td>\n",
       "      <td>@sasha_feather @hypatiadotca Thank you so much...</td>\n",
       "      <td>Google</td>\n",
       "      <td>thank reminder! we’re it, sorry lapse.</td>\n",
       "      <td>thank reminder! we’re it, sorry lapse.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057837349290287104</td>\n",
       "      <td>Text (1/2):\\n1. An end to Forced Arbitration i...</td>\n",
       "      <td>Google</td>\n",
       "      <td>end forced_arbitration cases harassment dis...</td>\n",
       "      <td>end cases harassment discrimination current...</td>\n",
       "      <td>forced_arbitration sexual_harassment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1058058822500188160</td>\n",
       "      <td>Hundreds of Google employees (some carrying si...</td>\n",
       "      <td>Google</td>\n",
       "      <td>hundreds employees carrying signs gathering ce...</td>\n",
       "      <td>hundreds employees carrying signs gathering ce...</td>\n",
       "      <td>sexual_misconduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1058059546332139520</td>\n",
       "      <td>greatest sign or greatest sign #googlewalkout ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>greatest sign greatest sign</td>\n",
       "      <td>greatest sign greatest sign</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1058059737932140545</td>\n",
       "      <td>We see you, Google Kirkland! #GoogleWalkout ht...</td>\n",
       "      <td>Google</td>\n",
       "      <td>you, kirkland!</td>\n",
       "      <td>you, kirkland!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1058059938344456193</td>\n",
       "      <td>Thanks for braving the cold, Google Seattle! #...</td>\n",
       "      <td>Google</td>\n",
       "      <td>thanks braving cold, seattle!</td>\n",
       "      <td>thanks braving cold, seattle!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1058060088240496643</td>\n",
       "      <td>Google San Francisco, great turnout! #GoogleWa...</td>\n",
       "      <td>Google</td>\n",
       "      <td>san francisco, great turnout!</td>\n",
       "      <td>san francisco, great turnout!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                    original_tweets  \\\n",
       "0   1057794087955427328  Tomorrow, we walk out for real change. #google...   \n",
       "1   1057804203895283712  We, Google employees and contractors, will wal...   \n",
       "2   1057826104965246976  Google employees and contractors will be leavi...   \n",
       "3   1057836978954256385  @sasha_feather @hypatiadotca Thank you so much...   \n",
       "4   1057837349290287104  Text (1/2):\\n1. An end to Forced Arbitration i...   \n",
       "..                  ...                                                ...   \n",
       "95  1058058822500188160  Hundreds of Google employees (some carrying si...   \n",
       "96  1058059546332139520  greatest sign or greatest sign #googlewalkout ...   \n",
       "97  1058059737932140545  We see you, Google Kirkland! #GoogleWalkout ht...   \n",
       "98  1058059938344456193  Thanks for braving the cold, Google Seattle! #...   \n",
       "99  1058060088240496643  Google San Francisco, great turnout! #GoogleWa...   \n",
       "\n",
       "   company_name                                      ngram_to_text  \\\n",
       "0        Google                     tomorrow, walk real change.      \n",
       "1        Google  we, employees contractors, walkout november :a...   \n",
       "2        Google  employees contractors leaving flyers desks tom...   \n",
       "3        Google             thank reminder! we’re it, sorry lapse.   \n",
       "4        Google     end forced_arbitration cases harassment dis...   \n",
       "..          ...                                                ...   \n",
       "95       Google  hundreds employees carrying signs gathering ce...   \n",
       "96       Google                        greatest sign greatest sign   \n",
       "97       Google                                     you, kirkland!   \n",
       "98       Google                      thanks braving cold, seattle!   \n",
       "99       Google                      san francisco, great turnout!   \n",
       "\n",
       "                                     unigrams_to_text  \\\n",
       "0                      tomorrow, walk real change.      \n",
       "1   we, employees contractors, walkout november :a...   \n",
       "2   employees contractors leaving flyers desks tom...   \n",
       "3              thank reminder! we’re it, sorry lapse.   \n",
       "4      end cases harassment discrimination current...   \n",
       "..                                                ...   \n",
       "95  hundreds employees carrying signs gathering ce...   \n",
       "96                        greatest sign greatest sign   \n",
       "97                                     you, kirkland!   \n",
       "98                      thanks braving cold, seattle!   \n",
       "99                      san francisco, great turnout!   \n",
       "\n",
       "                         bigrams_to_text  \n",
       "0                                         \n",
       "1                                         \n",
       "2                                         \n",
       "3                                         \n",
       "4   forced_arbitration sexual_harassment  \n",
       "..                                   ...  \n",
       "95                     sexual_misconduct  \n",
       "96                                        \n",
       "97                                        \n",
       "98                                        \n",
       "99                                        \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_santanize.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_santanize['tweet_id'] = df_santanize['tweet_id'].apply(str)\n",
    "\n",
    "# create excel writer object\n",
    "writer1 = pd.ExcelWriter('sanitized_data.xlsx')\n",
    "# write dataframe to excel\n",
    "df_santanize.to_excel(writer1, sheet_name = 'sanitized_text', engine=\"xlsxwriter\")\n",
    "\n",
    "# save the excel\n",
    "writer1.save()\n",
    "#writer.close()\n",
    "print('DataFrame is written successfully to Excel File.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
